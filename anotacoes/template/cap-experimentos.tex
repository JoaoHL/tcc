%% ------------------------------------------------------------------------- %%
\chapter{Experimentos}
\label{cap:experimentos}

Este capítulo descreve os experimentos feitos com os códigos desenvolvidos, especificando ambientes, configurações e metodologia utilizados para avaliar o desempenho da implementação dos algoritmos em \textit{hardware}, via síntese de alto nível, e \textit{software}.

\section{Metodologia}

\subsection{Configurações dos algoritmos}

Para a execução dos experimentos, tamanhos de entrada específicos foram utilizados em cada um dos algoritmos. As entradas foram utilizadas igualmente em ambas as implementações em \textit{software} e \textit{hardware}.

O algoritmo de Huffman foi configurado com um texto de $682$ caracteres, parte de um texto de teste chamado \textit{Lorem ipsum}, gerado automaticamente por diversas ferramentas \textit{online}. O alfabeto utilizado foi a tabela ASCII, contendo 128 caracteres (incluindo os não-imprimíveis). Para testar a ordem de tempo de execução do programa, foram usados textos \textit{Lorem Ipsum} de tamanhos $n$ tais que $n \in$ \{682, 1364, 2046, 2728, 3410, 4092, 4774, 5456, 6138, 6820, 7502, 8184, 8866, 9548, 10230, 10912\}.

A 2-aproximação do TSP recebeu como entrada um número $m$ representando o número de vértices do grafo, tal que $m \in$ \{12, 24, 36, 48, 60, 72, 84, 96, 108, 120, 132, 144, 156, 168, 180, 192\}. 

O tamanho e quantidade das instâncias de ambos os algoritmos foram escolhidas visando uma visualização melhor dos dados, junto de uma maior verossimilhança com a realidade. Ambos os algoritmos tiveram o tamanho de suas instâncias uniformemente espaçados em $682$ caracteres no algoritmo de Huffman, e $12$ vértices no algoritmo de Rosenkrantz-Stearn-Lewis. Devido ao ambiente usado na simulação (uma máquina virtual Java), as simulações demoraram substancialmente, a ponto de demorar $24$ horas e $3$ minutos para $m = 192$. O tamanho máximo do texto no algoritmo de Huffman foi limitado em $10912$ caracteres devido ao esgotamento da memória interna do modelo de placa usado na simulação. Apesar disso, os testes foram suficientes para mostrar a curva de crescimento da quantidade de ciclos de \textit{clock} em função do tamanho das entradas.

\subsection{Implementação em software}

A execução dos algoritmos implementados em \textit{software} foi feita com o uso do \textit{profiler} \textit{OProfile}\footnote{\url{http://oprofile.sourceforge.net/news/}}, disponível no repositório padrão da distribuição Ubuntu do sistema operacional Linux. O \textit{OProfile} consegue medir uma contagem aproximada de eventos do processador que ocorrem durante a execução de um programa. No caso deste trabalho, ele foi utilizado para contar a quantidade total de ciclos de \textit{clock} executados enquanto o processo especificado estava sendo executado, usando o comando \texttt{ocount} do OProfile. Por "quantidade total" entende-se a quantidade de ciclos que todos os processos usaram, não apenas os ciclos nos quais os programas a serem testados usavam o processador. Tal técnica foi adotada pois foi considerada mais verossímil com a realidade, onde circuitos de propósito geral frequentemente têm vários processos em execução.

Apesar do interesse em se medir também o número de acessos à memória, a dificuldade em se instrumentar essa medição nos algoritmos em \textit{hardware} faria com que o resultado não fosse utilizado, devido à falta de dados da execução em \textit{hardware} para comparação.

A compilação dos códigos foi feita usando o compilador da linguagem C \texttt{gcc} versão $5.4.0$, sem nenhuma opção de otimização. A execução foi realizada $15$ vezes via terminal em um computador com processador Intel Core $i5$, com dois núcleos de $1.8$ GHz (totalizando frequência de $3.2$ GHz em programas paralelizáveis), com aproximadamente $10$ \textit{gigabytes} de memória DDR3.

\subsection{Implementação em hardware}

Os códigos C criados no desenvolvimento dos algoritmos descritos foram utilizados como entrada do LegUp no fluxo de puro \textit{hardware}. Não foram utilizadas opções de otimização, como as de compilação do compilador \textit{clang}, ou as de emparelhamento e escalonamento, como \textit{pipelining} de laços ou compartilhamento de unidades funcionais de adição.

Devido à dificuldade em lidar com as saídas serializadas da placa, foi executada $1$ simulação por entrada e por algoritmo, utilizando a ferramenta \textit{ModelSim}, dispobilizada pela Intel junto da ferramenta de programação de FPGAs \textit{Quartus Prime}\footnote{\url{https://www.intel.com/content/www/us/en/software/programmable/quartus-prime/overview.html}}. Inicialmente, mais simulações de \textit{hardware} foram feitas por instância de teste, mas como as medidas iniciais apresentaram variância e desvio padrão iguais a $0$, os testes subsequentes foram executados uma única vez. O \textit{ModelSim}\footnote{\url{https://www.intel.com/content/www/us/en/software/programmable/quartus-prime/model-sim.html}} foi executado através de uma opção de execução do \textit{makefile} do LegUp, dada a disponibilidade do arquivo Verilog gerado pela síntese de alto nível.

O \textit{bitcode} gerado pelo fluxo do LegUp foi programado na FPGA a fim de testar se o resultado da síntese era relevante para fins práticos. Após uma pequena modificação no código para acender um LED caso o resultado do algoritmo fosse correto, a placa foi programada e o resultado foi positivo, executando os algoritmos e acendendo o LED dado o resultado correto da execução. Vale notar que o tempo de compilação do RTL para \textit{bitcode} e transferência deste para a placa FPGA através do Intel Quartus Prime foi consideravelmente alto, variando entre 6 e 8 minutos para sua execução completa.

A placa utilizada foi a Helio Board SoC FPGA, cujo \textit{chip} FPGA é uma Intel Cyclone V, modelo 5CSXFC6C6U23C\footnote{Mais informações sobre a placa: \url{https://rocketboards.org/foswiki/Documentation/MacnicaHelioSoCEvaluationKit}}. Dentre os recursos disponíveis, destaca-se a presença de $41.509$ BLCs, $110.000$ BLBs e $557$ blocos M10K de memória RAM que totalizam $696.250$ bytes de memória.
Ambas as execuções via simulação e via programação da placa usaram uma frequência de \textit{clock} de $70$ MHz.

\section{Resultados}

Os resultados das experiências com respeito ao algoritmo de Huffman são mostrados nas tabelas \ref{tabela-simulacao-software-huffman} e \ref{tabela-simulacao-hardware-huffman}. Os gráficos \ref{fig:grafico-huffman}, construídos a partir dos dados dessas tabelas, ilustram o aspecto linear da ordem de tempo de execução do algoritmo para um texto suficientemente maior que o tamanho do alfabeto adotado no programa. As barras verticais ortogonais à curva do primeiro gráfico em \ref{fig:grafico-huffman} indicam o intervalo de confiança de $95\%$ sobre o conjunto amostral das experiências. O intervalo não se aplica às execuções em \textit{hardware} pois dada a natureza determinística da execução da simulação no ambiente usado, não houve variação no número de ciclos de \textit{clock} para duas execuções da mesma instância dos algoritmos.

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|} \hline
		Número de caracteres & Média (ciclos de \textit{clock}) & Desvio padrão\\\hline
		682 &  816.830  & 29.301,11 \\\hline
		1.364 & 841.969 & 26.246,27 \\\hline
		2.046 & 919.522 & 29.937,78 \\\hline
		2.728 & 946.833 & 50.362,63 \\\hline
		3.410 & 975.786 & 79.094,14 \\\hline
		4.092 & 978.415 & 51.311,15 \\\hline
		4.774 & 964.691 & 35.301,45 \\\hline
		5.456 & 990.615 & 31.539,49 \\\hline
		6.138 & 996.154 & 59.283,06 \\\hline
		6.820 & 1.006.365 & 44.616,39 \\\hline
		7.502 & 1.012.693 & 33.215,43 \\\hline
		8.184 & 1.017.322 & 24.861,31 \\\hline
		8.866 & 1.025.059 & 24.720,50 \\\hline
		9.548 & 1.038.327 & 49.803,70 \\\hline
		10.230 & 1.037.896 & 35.646,26 \\\hline
		10.912 & 1.053.150 & 37.941,55 \\\hline
	\end{tabular}
	\caption{\label{tabela-simulacao-software-huffman}Dados das execuções do algoritmo de Huffman em software}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|} \hline
		Número de caracteres & Ciclos de \textit{clock}\\
		\hline
		682 & 12.066 \\\hline
		1.364 & 16.158 \\\hline
		2.046 & 20.250 \\\hline
		2.728 & 24.342 \\\hline
		3.410 & 28.434 \\\hline
		4.092 & 32.526 \\\hline
		4.774 & 36.618 \\\hline
		5.456 & 40.710 \\\hline
		6.138 & 44.802 \\\hline
		6.820 & 48.894 \\\hline
		7.502 & 52.986 \\\hline
		8.184 & 57.078 \\\hline
		8.866 & 61.170 \\\hline
		9.548 & 65.262 \\\hline
		10.230 & 69.354 \\\hline
		10.912 & 74.235 \\\hline
	\end{tabular}
	\caption{\label{tabela-simulacao-hardware-huffman}Dados da simulação em hardware do algoritmo de Huffman}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{figuras/grafico-huffman-software}
	\includegraphics[width=8cm]{figuras/grafico-huffman-hardware}
	\caption{\label{fig:grafico-huffman}Comparação de ciclos de clock do algoritmo de Huffman entre execuções em software (à esquerda) e hardware (à direita).}
\end{figure}

Para os experimentos feitos com o algoritmo de Rosenkrantz-Stearn-Lewis, os dados gerados são representados nas tabelas \ref{tabela-simulacao-software-tsp} e \ref{tabela-simulacao-hardware-tsp}, bem como nos gráficos presentes em \ref{fig:grafico-tsp}. Nota-se o caráter quadrático da ordem do tempo de execução do algoritmo. Da mesma forma que o algoritmo de Huffman, foi adotado um intervalo de confiança de $95\%$ com base no conjunto amostral de experiências.

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|} \hline
		Tamanho da entrada (vértices) & Média (ciclos de \textit{clock}) & Desvio padrão\\\hline
		12  & 979.847     & 4.966,96 \\\hline
		24  & 1.376.867   & 62.074,81 \\\hline
		36  & 2.544.276   & 36.565,32 \\\hline
		48  & 4.238.226   & 25.501,12 \\\hline
		60  & 7.290.301   & 95.772,14 \\\hline
		72  & 12.240.208   & 188.018,34 \\\hline
		84  & 18.376.907   & 317.427,61 \\\hline
		96  & 25.392.184  & 174.893,74 \\\hline
		108  & 36.580.303   & 651.705,61 \\\hline
		120  & 45.496.549   & 1.277.070,90 \\\hline
		132  & 63.995.800   & 1.383.403,12 \\\hline
		144  & 82.581.032   & 1.260.099,51 \\\hline
		156  & 104.586.325   & 1.046.594,03 \\\hline
		168  & 129.343.059   & 878.890,74 \\\hline
		180  & 150.005.045   & 1.107.449,01 \\\hline
		192 & 184.441.878 & 441.135,94 \\\hline
	\end{tabular}
	\caption{\label{tabela-simulacao-software-tsp}Dados das execuções do algoritmo de Rosenkrantz-Stearn-Lewis em software}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|} \hline
		Tamanho da entrada (vértices) & Ciclos de \textit{clock}\\
		\hline
		12  & 41.855 \\\hline
		24  & 229.790 \\\hline
		36  & 655.461 \\\hline
		48  & 1.405.427 \\\hline
		60  & 2.580.465 \\\hline
		72  & 4.253.286 \\\hline
		84  & 6.547.620 \\\hline
		96  & 9.519.171 \\\hline
		108  & 13.280.668 \\\hline
		120  & 17.911.164 \\\hline
		132 &  23.519.271 \\\hline
		144  & 30.181.566 \\\hline
		156  & 38.028.744 \\\hline
		168  & 47.178.533 \\\hline
		180  & 57.484.346 \\\hline
		192 & 69.323.457 \\\hline
	\end{tabular}
	\caption{\label{tabela-simulacao-hardware-tsp}Dados da simulação em hardware do algoritmo de Rosenkrantz-Stearn-Lewis}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{figuras/grafico-tsp-software}
	\includegraphics[width=8cm]{figuras/grafico-tsp-hardware}
	\caption{\label{fig:grafico-tsp}Comparação de ciclos de clock do algoritmo de Rosenkrantz-Stearn-Lewis entre execuções em software (à esquerda) e hardware (à direita).}
\end{figure}

Ambos os gráficos apontam que o crescimento do tempo de execução no ambiente de \textit{software} é maior que no ambiente de \textit{hardware}. A causa mais provável para esse fenômeno é o fato de que ao aumentar o tamanho da entrada do \textit{software}, são necessários mais períodos de escalonamento dos processos por parte do sistema operacional, já que o tempo de execução dos programas em si aumenta. Em \textit{hardware}, como todo o processamento é dedicado à execução dos algoritmos (uma vez que o circuito foi construído especificamente para a execução do algoritmo), não há \textit{overhead} gerado pela execução da troca de contexto dos escalonadores, nem ociosidade do algoritmo enquanto outros processos são executados. Ou seja: em \textit{hardware}, os algoritmos estão sendo executados $100\%$ do tempo.

Mesmo com a exclusividade dos algoritmos em usar os recursos da placa, vale lembrar que a diferença entre as frequências de \textit{clock} máxima de um \textit{chip} ASIC (como um processador Intel) e de uma placa FPGA é de $1$ ou $2$ ordens de grandezas. Por exemplo, a frequência máxima da placa usada nos experimentos é de $100$ MHz, contra $3.2$ GHz da máquina utilizada para executar os \textit{softwares}, apresentando uma proporção de $1$ para $32$ ciclos de \textit{clock} entre os dispositivos. No caso das máquinas usadas neste trabalho, a placa FPGA e o computador executavam, respectivamente, $1$ ciclo de \textit{clock} a cada $1,4 \times 10^{-8}$ e $5,6 \times 10^{-10}$ segundos. Usando os dados do algoritmo de Huffman para um texto de $5.456$ caracteres, o tempo de execução (em segundos) em \textit{hardware} e \textit{software} apresentados em \ref{calculo-tempo-hardware-huffman} e \ref{calculo-tempo-software-huffman}.

\begin{equation}
\label{calculo-tempo-hardware-huffman}
\centering
1,4 \times 10^{-8} \times 40.710 = 5,6994 \times 10^{-4}s
\end{equation}

\begin{equation}
\label{calculo-tempo-software-huffman}
\centering
5,6 \times 10^{-10} \times 990.615 = 5,5474 \times 10^{-4}s
\end{equation}

Da mesma forma, para o algoritmo de Rosenkrantz-Stern-Lewis, para um grafo de $192$ vértices, temos o tempo de execução, em segundos e respectivamente, para os experimentos em \textit{hardware} e \textit{software}  apresentados em \ref{calculo-tempo-hardware-tsp} e \ref{calculo-tempo-software-tsp}.

\begin{equation}
\label{calculo-tempo-hardware-tsp}
\centering
1,4 \times 10^{-8} \times 69.323.457 = 9,7053 \times 10^{-1}s
\end{equation}

\begin{equation}
\label{calculo-tempo-software-tsp}
\centering
5,6 \times 10^{-10} \times 184.441.878 = 1,0328 \times 10^{-1}s
\end{equation}

Há evidências, portanto, de que a utilização de um \textit{hardware} dedicado, implementado em um \textit{chip} FPGA, e uma máquina de propósito geral podem apresentar desempenhos muito similares no que diz respeito ao tempo de execução, mas altamente discrepantes em termos de ciclos de \textit{clock}.

