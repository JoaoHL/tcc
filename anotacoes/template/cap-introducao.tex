%% ------------------------------------------------------------------------- %%
\chapter{Introdução}
\label{cap:introducao}

A melhoria do desempenho dos computadores sempre foi uma constante na história da Computação. Das válvulas a vácuo até os nanotransístores, por muito tempo o desenvolvimento de \textit{hardware} foi regido pela Lei de Moore, dizendo que a cada 18 meses a quantidade de transístores em um \textit{chip} de silício dobraria e, por consequência, seu desempenho. Atualmente, tal lei chega aos limites da Física Moderna, onde um nanotransístor de 1 nanômetro de comprimento já foi inventado\footnote{\url{http://science.sciencemag.org/content/354/6308/99}}. Novas técnicas estão sendo estudadas e aplicadas na melhoria da fabricação de \textit{chip}s, como a manipulação de novos tipos de partículas físicas\footnote{\url{https://www.nature.com/articles/nnano.2017.178}} e de propriedades quânticas de partículas já existentes, como o \textit{spin}\footnote{\url{https://arxiv.org/abs/1212.3362}}.

Para impulsionar o desempenho computacional sem envolver diretamente a quantidade de transístores em um \textit{chip} ou as propriedades das partículas envolvidas na fabricação, novas metodologias computacionais foram adotadas. Por exemplo, a paralelização do processamento de dados a partir do trabalho conjunto entre \textit{hardwares} dedicados e de propósito geral tem sido amplamente empregada em aplicações que demandam baixa latência de resposta, como processamento gráfico\footnote{\url{https://link.springer.com/chapter/10.1007/3-540-63508-4_107}} e gerenciamento de memória\footnote{\url{https://patents.google.com/patent/US9652230}}. Um bom exemplo de \textit{hardware} dedicado é a \textit{GPU} (\textit{Graphics Processing Unit}), criada com o intuito de paralelizar o processamento gráfico de computadores de uso geral a fim de acelerar a visualização das interfaces gráficas destes.

Apesar do desempenho adquirido no uso de \textit{hardwares} dedicados, é necessário um grande esforço para inventar ou otimizar dispositivos. O ciclo de desenvolvimento de um novo \textit{chip} vai desde o planejamento do circuito até a encomenda de fabricação de amostras para testar seu funcionamento. O custo e tempo envolvidos podem ser proibitivos, na maioria das aplicações, envolvendo meses de pesquisas e milhares de reais ou dólares por ciclo. Uma das soluções encontradas recentemente para acelerar e baratear esse processo foi o investimento na evolução de \textit{hardwares} reprogramáveis, como as PALs (\textit{Programmable Array Logic}), até a criação dos FPGAs.

Os FPGAs são \textit{chips} de silício reprogramáveis que podem, dentro de seus limites, recriar qualquer circuito lógico. Essa característica o faz interessante no ciclo de desenvolvimento de \textit{hardware} devido à facilidade em se ter um \textit{hardware} com um algoritmo personalizado, programado e de alteração relativamente fácil.

Apesar das facilidades trazidas com a evolução dos FPGAs, há uma demanda no mercado por pesquisadores e desenvolvedores de \textit{hardware}. Devido às dificuldades citadas com a Lei de Moore, seria interessante ter uma maior quantidade de pesquisas em novas tecnologias e arquiteturas de circuitos para manter o crescimento de desempenho os computadores. Por exemplo, a proporção entre a quantidade de profissionais das áreas de engenharia de \textit{software} e \textit{hardware} é de $10$ para $1$, como citado pelo Bureau de Estatística Trabalhista dos EUA EM 2010.

Uma solução para a situação seria adotar formas de aproximar essas duas áreas de engenharia, integrando ambos os profissionais de \textit{software} e \textit{hardware} em uma mesma tarefa. Essa possibilidade é dada pelo uso de ferramentas de síntese de alto nível, onde um engenheiro de \textit{software} pode programar um algoritmo arbitrariamente complexo e traduzí-lo em uma especificação de \textit{hardware}, que pode ser otimizada pelo engenheiro de \textit{hardware}. A síntese de alto nível é, portanto, a criação de algoritmos em \textit{hardware} através das descrições destes por linguagens de alto nível, tais como C.

A fim de pesquisar sobre essa solução, o presente trabalho explica sobre o que é e como funcionam FPGAs e síntese de alto nível nos capítulos \ref{cap:fpga} e \ref{cap:conceitos}. Foi escolhida uma ferramenta de síntese de alto nível chamada \textit{LegUp High-Level Synthesis}, que é descrita no capítulo \ref{cap:legup}. Para testar o processo de síntese da ferramenta, foram estudados e programados dois algoritmos, cujos contextos são dados no capítulo \ref{cap:algoritmos}. Depois de desenvolvidos os algoritmos e \textit{hardwares} equivalentes, suas qualidades de processamento foram avaliadas a partir da contagem de ciclos de \textit{clock} utilizados para concluir suas execuções. Os resultados das avaliações são dados no capítulo \ref{cap:experimentos}.
